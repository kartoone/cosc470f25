{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d8568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils as vutils\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Models\n",
    "# ---------------------------\n",
    "class Generator(nn.Module):\n",
    "    # Outputs 28x28 from latent z of size nz\n",
    "    def __init__(self, *, nz: int = 100, ngf: int = 64, nc: int = 1):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # z -> 512x7x7\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 7, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 512x7x7 -> 256x14x14\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 256x14x14 -> 128x28x28\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 128x28x28 -> nc x 28x28\n",
    "            nn.ConvTranspose2d(ngf * 2, nc, 3, 1, 1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        print(\"forward\")\n",
    "        return self.main(z)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    # Returns a single logit per image\n",
    "    def __init__(self, *, nc: int = 1, ndf: int = 64):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 28x28 -> 14x14\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 14x14 -> 7x7\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 7x7 -> 1x1 (logit channel)\n",
    "            nn.Conv2d(ndf * 2, 1, 7, 1, 0, bias=False),\n",
    "            # No Sigmoid (we use BCEWithLogitsLoss)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main(x)          # [B,1,1,1]\n",
    "        return out.view(-1, 1)      # [B,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e33243",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 888\n",
    "nc=1\n",
    "nz=100\n",
    "ngf = 64\n",
    "batch_size = 10\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "epochs = 10\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparameter for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "data_root = \"/workspaces/cosc470/data\"\n",
    "\n",
    "set_seed(seed)\n",
    "device = get_device()\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Using nc={nc}, nz={nz}, ngf={ngf}, ndf={ndf}\")\n",
    "\n",
    "# Data\n",
    "tfm = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize((0.5,), (0.5,)),  # scale to [-1, 1]\n",
    "])\n",
    "dataset = datasets.MNIST(root=data_root, train=True, download=True, transform=tfm)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "# Models\n",
    "netG = Generator(nz=nz, ngf=ngf, nc=nc).to(device)\n",
    "netD = Discriminator(nc=nc, ndf=ndf).to(device)\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "print(netG)\n",
    "print(netD)\n",
    "\n",
    "# Quick sanity on shapes\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(4, nz, 1, 1, device=device)\n",
    "    fake = netG(z)\n",
    "    assert fake.shape == (4, nc, 28, 28), f\"G output shape wrong: {fake.shape}\"\n",
    "    x = torch.randn(4, nc, 28, 28, device=device)\n",
    "    y = netD(x)\n",
    "    assert y.shape == (4, 1), f\"D output shape wrong: {y.shape}\"\n",
    "    print(\"Sanity checks passed.\")\n",
    "\n",
    "# Loss & Optims\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4942fedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[1/10][100/6000] Loss_D: 1.0419 (R 0.5975 F 0.4443) Loss_G: 1.0590\n",
      "[1/10][200/6000] Loss_D: 1.3343 (R 0.8783 F 0.4560) Loss_G: 0.9857\n",
      "[1/10][300/6000] Loss_D: 1.3431 (R 0.6130 F 0.7302) Loss_G: 1.1688\n",
      "[1/10][400/6000] Loss_D: 1.3284 (R 0.6827 F 0.6457) Loss_G: 0.9725\n",
      "[1/10][500/6000] Loss_D: 1.2379 (R 0.5759 F 0.6620) Loss_G: 0.8616\n",
      "[1/10][600/6000] Loss_D: 1.2589 (R 0.6731 F 0.5857) Loss_G: 1.2272\n",
      "[1/10][700/6000] Loss_D: 1.4340 (R 0.7019 F 0.7321) Loss_G: 0.8875\n",
      "[1/10][800/6000] Loss_D: 1.2854 (R 0.9072 F 0.3781) Loss_G: 1.2174\n",
      "[1/10][900/6000] Loss_D: 1.0652 (R 0.6541 F 0.4111) Loss_G: 1.3797\n",
      "[1/10][1000/6000] Loss_D: 1.4201 (R 0.8010 F 0.6191) Loss_G: 0.8394\n",
      "[1/10][1100/6000] Loss_D: 1.4974 (R 1.0915 F 0.4059) Loss_G: 0.6887\n",
      "[1/10][1200/6000] Loss_D: 1.4059 (R 0.8743 F 0.5317) Loss_G: 0.9865\n",
      "[1/10][1300/6000] Loss_D: 0.8867 (R 0.4121 F 0.4747) Loss_G: 1.1641\n",
      "[1/10][1400/6000] Loss_D: 1.0480 (R 0.3365 F 0.7115) Loss_G: 1.1371\n",
      "[1/10][1500/6000] Loss_D: 1.2966 (R 0.5706 F 0.7260) Loss_G: 1.3116\n",
      "[1/10][1600/6000] Loss_D: 1.4064 (R 0.9735 F 0.4328) Loss_G: 1.1500\n",
      "[1/10][1700/6000] Loss_D: 1.2152 (R 0.4607 F 0.7545) Loss_G: 1.1043\n",
      "[1/10][1800/6000] Loss_D: 1.1535 (R 0.5362 F 0.6173) Loss_G: 0.9819\n",
      "[1/10][1900/6000] Loss_D: 1.4572 (R 0.7119 F 0.7454) Loss_G: 0.8892\n",
      "[1/10][2000/6000] Loss_D: 1.1773 (R 0.3660 F 0.8113) Loss_G: 1.2122\n",
      "[1/10][2100/6000] Loss_D: 1.8794 (R 0.9616 F 0.9178) Loss_G: 0.6836\n",
      "[1/10][2200/6000] Loss_D: 1.4302 (R 0.3014 F 1.1289) Loss_G: 1.1929\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m lossD_real\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     28\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(bsz, nz, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 29\u001b[0m fake \u001b[38;5;241m=\u001b[39m \u001b[43mnetG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m                     \u001b[38;5;66;03m# [B,1,28,28]\u001b[39;00m\n\u001b[0;32m     30\u001b[0m labels_fake \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((bsz, \u001b[38;5;241m1\u001b[39m), fake_label, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     31\u001b[0m out_fake \u001b[38;5;241m=\u001b[39m netD(fake\u001b[38;5;241m.\u001b[39mdetach())         \u001b[38;5;66;03m# [B,1]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 65\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, z):\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:952\u001b[0m, in \u001b[0;36mConvTranspose2d.forward\u001b[1;34m(self, input, output_size)\u001b[0m\n\u001b[0;32m    947\u001b[0m num_spatial_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    948\u001b[0m output_padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_padding(\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;28minput\u001b[39m, output_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    950\u001b[0m     num_spatial_dims, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m--> 952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_transpose2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_padding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Fixed noise for monitoring\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Output dir\n",
    "out_dir = Path(\"samples\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Labels (shape [B,1])\n",
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for i, (real, _) in enumerate(dataloader, start=1):\n",
    "        bsz = real.size(0)\n",
    "        real = real.to(device, non_blocking=True)\n",
    "\n",
    "        # -----------------\n",
    "        # Train Discriminator: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        # -----------------\n",
    "        netD.zero_grad(set_to_none=True)\n",
    "\n",
    "        labels_real = torch.full((bsz, 1), real_label, device=device, dtype=torch.float32)\n",
    "        out_real = netD(real)                  # [B,1]\n",
    "        lossD_real = criterion(out_real, labels_real)\n",
    "        lossD_real.backward()\n",
    "\n",
    "        noise = torch.randn(bsz, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)                     # [B,1,28,28]\n",
    "        labels_fake = torch.full((bsz, 1), fake_label, device=device, dtype=torch.float32)\n",
    "        out_fake = netD(fake.detach())         # [B,1]\n",
    "        lossD_fake = criterion(out_fake, labels_fake)\n",
    "        lossD_fake.backward()\n",
    "\n",
    "        optimizerD.step()\n",
    "        lossD = lossD_real + lossD_fake\n",
    "\n",
    "        # -----------------\n",
    "        # Train Generator: maximize log(D(G(z)))  (i.e., fool D to think fakes are real)\n",
    "        # -----------------\n",
    "        netG.zero_grad(set_to_none=True)\n",
    "        labels_gen = torch.full((bsz, 1), real_label, device=device, dtype=torch.float32)\n",
    "        out_fake_for_G = netD(fake)            # recompute; do not detach\n",
    "        lossG = criterion(out_fake_for_G, labels_gen)\n",
    "        lossG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"[{epoch}/{epochs}][{i}/{len(dataloader)}] \"\n",
    "                    f\"Loss_D: {lossD.item():.4f} (R {lossD_real.item():.4f} F {lossD_fake.item():.4f}) \"\n",
    "                    f\"Loss_G: {lossG.item():.4f}\")\n",
    "\n",
    "    # Save a grid each epoch\n",
    "    with torch.no_grad():\n",
    "        fake_fixed = netG(fixed_noise).cpu()\n",
    "    grid = vutils.make_grid(fake_fixed, padding=2, normalize=True, nrow=8)\n",
    "    vutils.save_image(grid, out_dir / f\"epoch_{epoch:03d}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ea5328f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Samples saved to: C:\\Users\\brtoone\\python\\cosc470-kartoone76\\cosc470\\notebooks\\samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Final sample\n",
    "import matplotlib.pyplot as plt\n",
    "with torch.no_grad():\n",
    "    set_seed(555)\n",
    "    z1 = torch.randn(1, nz, 1, 1, device=device)\n",
    "    z2 = torch.add(z1, -1.9)\n",
    "    final_fake1 = netG.forward(z1)\n",
    "    final_fake2 = netG.forward(z2)\n",
    "    img_fake1 = final_fake1[0].reshape((28,28,1))\n",
    "    img_fake2 = final_fake2[0].reshape((28,28,1))\n",
    "    plt.imshow(img_fake1, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    plt.imshow(img_fake2, cmap=\"gray\")\n",
    "print(f\"Done. Samples saved to: {out_dir.resolve()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed32bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
