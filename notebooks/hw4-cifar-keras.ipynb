{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee003639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: keras in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (3.11.3)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from torchvision) (2.3.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from keras) (2.3.1)\n",
      "Requirement already satisfied: rich in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from keras) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from keras) (3.14.0)\n",
      "Requirement already satisfied: optree in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from keras) (0.17.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from keras) (0.5.3)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.3-cp313-cp313-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.75.0-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from rich->keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from rich->keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\brtoone\\python\\cosc470\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl (332.0 MB)\n",
      "   ---------------------------------------- 0.0/332.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.4/332.0 MB 34.2 MB/s eta 0:00:10\n",
      "    --------------------------------------- 6.6/332.0 MB 18.4 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 15.2/332.0 MB 27.0 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 24.4/332.0 MB 31.9 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 31.7/332.0 MB 32.4 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 38.0/332.0 MB 32.4 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 44.8/332.0 MB 32.4 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 51.9/332.0 MB 32.5 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 58.7/332.0 MB 32.7 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 66.1/332.0 MB 32.9 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 73.1/332.0 MB 33.1 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 80.7/332.0 MB 33.3 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 87.8/332.0 MB 33.5 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 95.4/332.0 MB 33.6 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 102.8/332.0 MB 33.8 MB/s eta 0:00:07\n",
      "   ------------ -------------------------- 109.8/332.0 MB 33.9 MB/s eta 0:00:07\n",
      "   ------------- ------------------------- 118.0/332.0 MB 34.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 125.8/332.0 MB 34.2 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 131.1/332.0 MB 33.8 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 139.2/332.0 MB 34.0 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 146.8/332.0 MB 34.2 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 154.9/332.0 MB 34.4 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 163.3/332.0 MB 34.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 170.9/332.0 MB 34.7 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 178.5/332.0 MB 34.8 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 186.9/332.0 MB 35.0 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 194.5/332.0 MB 35.0 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 200.8/332.0 MB 34.8 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 206.3/332.0 MB 34.5 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 212.1/332.0 MB 34.3 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 217.6/332.0 MB 34.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 223.9/332.0 MB 34.0 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 229.6/332.0 MB 33.8 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 236.2/332.0 MB 33.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 242.7/332.0 MB 33.6 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 248.8/332.0 MB 33.5 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 255.3/332.0 MB 33.4 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 261.6/332.0 MB 33.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 268.2/332.0 MB 34.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 275.0/332.0 MB 33.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 281.8/332.0 MB 33.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 288.6/332.0 MB 33.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 295.7/332.0 MB 33.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 300.7/332.0 MB 32.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 307.0/332.0 MB 32.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 314.0/332.0 MB 32.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 321.1/332.0 MB 32.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  327.4/332.0 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 332.0/332.0 MB 30.7 MB/s  0:00:10\n",
      "Downloading grpcio-1.75.0-cp313-cp313-win_amd64.whl (4.6 MB)\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.6/4.6 MB 27.6 MB/s  0:00:00\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 29.7 MB/s  0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 6.8/26.4 MB 32.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 13.4/26.4 MB 32.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.7/26.4 MB 32.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 32.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 30.5 MB/s  0:00:00\n",
      "Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-1.17.3-cp313-cp313-win_amd64.whl (38 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, wheel, werkzeug, urllib3, termcolor, tensorboard-data-server, protobuf, opt_einsum, markdown, idna, grpcio, google_pasta, gast, charset_normalizer, certifi, tensorboard, requests, astunparse, tensorflow\n",
      "\n",
      "   ----------------------------------------  0/21 [libclang]\n",
      "   ----------------------------------------  0/21 [libclang]\n",
      "   --- ------------------------------------  2/21 [wrapt]\n",
      "   ----- ----------------------------------  3/21 [wheel]\n",
      "   ------- --------------------------------  4/21 [werkzeug]\n",
      "   ------- --------------------------------  4/21 [werkzeug]\n",
      "   ------- --------------------------------  4/21 [werkzeug]\n",
      "   --------- ------------------------------  5/21 [urllib3]\n",
      "   --------- ------------------------------  5/21 [urllib3]\n",
      "   --------------- ------------------------  8/21 [protobuf]\n",
      "   --------------- ------------------------  8/21 [protobuf]\n",
      "   --------------- ------------------------  8/21 [protobuf]\n",
      "   ----------------- ----------------------  9/21 [opt_einsum]\n",
      "   ------------------- -------------------- 10/21 [markdown]\n",
      "   ------------------- -------------------- 10/21 [markdown]\n",
      "   -------------------- ------------------- 11/21 [idna]\n",
      "   ---------------------- ----------------- 12/21 [grpcio]\n",
      "   ---------------------- ----------------- 12/21 [grpcio]\n",
      "   ---------------------- ----------------- 12/21 [grpcio]\n",
      "   ---------------------- ----------------- 12/21 [grpcio]\n",
      "   ------------------------ --------------- 13/21 [google_pasta]\n",
      "   ---------------------------- ----------- 15/21 [charset_normalizer]\n",
      "   ------------------------------ --------- 16/21 [certifi]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   ---------------------------------- ----- 18/21 [requests]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   ---------------------------------------- 21/21 [tensorflow]\n",
      "\n",
      "Successfully installed astunparse-1.6.3 certifi-2025.8.3 charset_normalizer-3.4.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.75.0 idna-3.10 libclang-18.1.1 markdown-3.9 opt_einsum-3.4.0 protobuf-6.32.1 requests-2.32.5 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 urllib3-2.5.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.3\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision matplotlib keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80fd97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "mnist_train = datasets.CIFAR10(\n",
    "    root='/workspaces/cosc470/data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "mnist_test = datasets.CIFAR10(\n",
    "    root='/workspaces/cosc470/data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0ad399b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001459C1F4400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "[[0.04320867 0.06792642 0.23629646 0.02631514 0.03995133 0.19009496\n",
      "  0.02023123 0.00839799 0.34536162 0.02221614]]\n",
      "6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brtoone\\python\\cosc470\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13033098 0.08907323 0.14034036 0.07851017 0.06890336 0.12637499\n",
      "  0.07351764 0.08296221 0.13175426 0.07823282]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import torch\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(20, kernel_size=5, activation='relu', input_shape=(32, 32, 3)),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "random_images = torch.randn(1, 32, 32, 3)\n",
    "bad_prediction = model.predict(random_images)\n",
    "print(bad_prediction)\n",
    "real_image = mnist_train[0][0].unsqueeze(0)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(mnist_train[0][0].permute(1, 2, 0))\n",
    "print(mnist_train[0][1])\n",
    "real_image_np = real_image.permute(0, 2, 3, 1).numpy()\n",
    "untrained_prediction = model.predict(real_image_np)\n",
    "print(untrained_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f580245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,520</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3920</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">392,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │         \u001b[38;5;34m1,520\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3920\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m392,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">394,630</span> (1.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m394,630\u001b[0m (1.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">394,630</span> (1.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m394,630\u001b[0m (1.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - acc: 0.2563 - loss: 2.0564 - val_acc: 0.3173 - val_loss: 1.9345\n",
      "Epoch 2/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - acc: 0.3476 - loss: 1.8442 - val_acc: 0.3688 - val_loss: 1.8084\n",
      "Epoch 3/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - acc: 0.3987 - loss: 1.7103 - val_acc: 0.4071 - val_loss: 1.6744\n",
      "Epoch 4/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - acc: 0.4323 - loss: 1.6065 - val_acc: 0.4352 - val_loss: 1.5801\n",
      "Epoch 5/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - acc: 0.4576 - loss: 1.5270 - val_acc: 0.4619 - val_loss: 1.5150\n",
      "Epoch 6/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - acc: 0.4833 - loss: 1.4574 - val_acc: 0.4875 - val_loss: 1.4519\n",
      "Epoch 7/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - acc: 0.5040 - loss: 1.4017 - val_acc: 0.4951 - val_loss: 1.4293\n",
      "Epoch 8/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - acc: 0.5182 - loss: 1.3588 - val_acc: 0.5276 - val_loss: 1.3654\n",
      "Epoch 9/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - acc: 0.5312 - loss: 1.3234 - val_acc: 0.5329 - val_loss: 1.3437\n",
      "Epoch 10/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - acc: 0.5420 - loss: 1.2944 - val_acc: 0.5429 - val_loss: 1.3198\n",
      "Epoch 11/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - acc: 0.5524 - loss: 1.2671 - val_acc: 0.5467 - val_loss: 1.3003\n",
      "Epoch 12/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - acc: 0.5604 - loss: 1.2436 - val_acc: 0.5480 - val_loss: 1.2906\n",
      "Epoch 13/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - acc: 0.5705 - loss: 1.2211 - val_acc: 0.5483 - val_loss: 1.2930\n",
      "Epoch 14/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - acc: 0.5769 - loss: 1.2010 - val_acc: 0.5592 - val_loss: 1.2580\n",
      "Epoch 15/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - acc: 0.5856 - loss: 1.1802 - val_acc: 0.5623 - val_loss: 1.2420\n",
      "Epoch 16/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - acc: 0.5913 - loss: 1.1618 - val_acc: 0.5711 - val_loss: 1.2330\n",
      "Epoch 17/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - acc: 0.5991 - loss: 1.1417 - val_acc: 0.5676 - val_loss: 1.2150\n",
      "Epoch 18/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - acc: 0.6070 - loss: 1.1244 - val_acc: 0.5733 - val_loss: 1.2146\n",
      "Epoch 19/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - acc: 0.6125 - loss: 1.1070 - val_acc: 0.5787 - val_loss: 1.2120\n",
      "Epoch 20/20\n",
      "\u001b[1m4250/4250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - acc: 0.6197 - loss: 1.0878 - val_acc: 0.5821 - val_loss: 1.1965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1458f147e00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 20\n",
    "\n",
    "x_train = torch.stack([mnist_train[i][0] for i in range(len(mnist_train))]).permute(0, 2, 3, 1).numpy()\n",
    "y_train = torch.tensor([mnist_train[i][1] for i in range(len(mnist_train))]).numpy()\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4dda477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 2.2791\n",
      "Epoch [2/20], Loss: 2.1904\n",
      "Epoch [3/20], Loss: 2.1592\n",
      "Epoch [4/20], Loss: 2.1369\n",
      "Epoch [5/20], Loss: 2.1121\n",
      "Epoch [6/20], Loss: 2.0912\n",
      "Epoch [7/20], Loss: 2.0717\n",
      "Epoch [8/20], Loss: 2.0527\n",
      "Epoch [9/20], Loss: 2.0382\n",
      "Epoch [10/20], Loss: 2.0241\n",
      "Epoch [11/20], Loss: 2.0104\n",
      "Epoch [12/20], Loss: 1.9966\n",
      "Epoch [13/20], Loss: 1.9831\n",
      "Epoch [14/20], Loss: 1.9695\n",
      "Epoch [15/20], Loss: 1.9570\n",
      "Epoch [16/20], Loss: 1.9453\n",
      "Epoch [17/20], Loss: 1.9343\n",
      "Epoch [18/20], Loss: 1.9247\n",
      "Epoch [19/20], Loss: 1.9169\n",
      "Epoch [20/20], Loss: 1.9086\n",
      "Test Accuracy: 53.95%\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set hyperparameters\n",
    "learning_rate = 0.005\n",
    "batch_size = 10\n",
    "epochs = 20\n",
    "\n",
    "# DataLoader for training\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "correct = 0\n",
    "for testimage in mnist_test:\n",
    "    a = testimage[0].unsqueeze(0)\n",
    "    a = model.forward(a)\n",
    "    if torch.argmax(a) == testimage[1]:\n",
    "        correct += 1\n",
    "print(f\"Test Accuracy: {100 * correct / len(mnist_test):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c20fae3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0360,  0.0051,  0.0409, -0.0254, -0.0344,  0.0075, -0.0296, -0.0069,\n",
      "          0.0157, -0.0281]], grad_fn=<AddmmBackward0>)\n",
      "6\n",
      "tensor([[-0.0003, -0.0102,  0.0236, -0.0063, -0.0254, -0.0136,  0.0083, -0.0021,\n",
      "          0.0099, -0.0079]], grad_fn=<AddmmBackward0>)\n",
      "Params:  108316554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/nn/functional.py:1535: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class AdvancedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AdvancedCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32 * 2, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32 * 2, out_channels=64 * 2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64 * 2, out_channels=64 * 2, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64 * 2, out_channels=128 * 2, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=128 * 2, out_channels=128 * 2, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=128 * 2, out_channels=128 * 2, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(in_channels=128 * 2, out_channels=256 * 2, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(in_channels=256 * 2, out_channels=256 * 2, kernel_size=3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(in_channels=256 * 2, out_channels=256 * 2, kernel_size=3, padding=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(32 * 2)\n",
    "        self.bn2 = nn.BatchNorm2d(128 * 2)\n",
    "        self.bn3 = nn.BatchNorm2d(256 * 2)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout2d(0.2)\n",
    "\n",
    "        self.fc1 = nn.Linear(4096 * 2, 4096 * 2)\n",
    "        self.fc2 = nn.Linear(4096 * 2, 2048 * 2)\n",
    "        self.fc3 = nn.Linear(2048 * 2, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.relu(self.bn2(self.conv4(x)))\n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.relu(self.conv6(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.relu(self.bn3(self.conv7(x)))\n",
    "        x = self.relu(self.conv8(x))\n",
    "        x = self.relu(self.conv9(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = AdvancedCNN()\n",
    "bad_prediction = model.forward(torch.randn(1, 3, 32, 32))\n",
    "print(bad_prediction)\n",
    "real_image = mnist_train[0][0].unsqueeze(0)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(mnist_train[0][0].permute(1, 2, 0))\n",
    "print(mnist_train[0][1])\n",
    "good_prediction = model.forward(real_image)\n",
    "print(good_prediction)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Params: \", count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99acd631",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[32m     25\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m optimizer.step()\n\u001b[32m     29\u001b[39m running_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set hyperparameters\n",
    "learning_rate = 0.005\n",
    "batch_size = 10\n",
    "epochs = 20\n",
    "\n",
    "# DataLoader for training\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    correct = 0\n",
    "    for testimage in mnist_test:\n",
    "        a = testimage[0].unsqueeze(0)\n",
    "        a = model.forward(a)\n",
    "        if torch.argmax(a) == testimage[1]:\n",
    "            correct += 1\n",
    "    print(f\"Test Accuracy: {100 * correct / len(mnist_test):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
